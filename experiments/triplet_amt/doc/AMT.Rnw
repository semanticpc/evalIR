\documentclass[prodmode,acmtecs]{reports}

% Package to generate and customize Algorithm as per ACM style
\usepackage[ruled]{algorithm2e}
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}


\usepackage[square,comma]{natbib}

% Metadata Information
\acmVolume{}
\acmNumber{}
\acmArticle{}
\acmYear{}
\acmMonth{}

% Document starts
\begin{document}

% Page heads
\markboth{Praveen Chandar}{Triplet Judgments using Mechanical Turk}

% Title portion
\title{Triplet Judgments using Mechanical Turk}
\author{Praveen Chandar
\affil{University of Delaware}}

\begin{abstract}

\end{abstract}

%\category{C.2.2}{Computer-Communication Networks}{Network Protocols}

%\terms{Design, Algorithms, Performance}

%\keywords{Wireless sensor networks, media access control,multi-channel, radio interference, time synchronization}

%\acmformat{}

%\begin{bottomstuff}
%\end{bottomstuff}

\maketitle


\section{Introduction}



The various steps involved are as follows:
\begin{bulletlist}
\item Document Pooling 
\item Generate and Sample triplets
\item Create HITs
\item Submit HITs
\end{bulletlist}


\section{Document Pooling}
The \emph{evalIR} package has a function to pool documents at a specified depth given a list of runs in TREC format. 

<<tidy=FALSE>>=
library(evalIR, quietly=T)
library(plyr)

source('../amtStudy.R')

runFiles <- list.files(path='../../../demo/data/diversity/trec2009', 
                       full.names=T)
runIDs <- basename(runFiles)
pooling_depth <- 5
runs <- read.runs(runPaths= runFiles, runids= runIDs, limit= 5)

# Document Pooling
pooled_docs <- adply(runs$getQueries(), 1, pool.documents, 
                     runs, pooling_depth)

head(pooled_docs, n=5)
@


\section{Generate and Sample Triplets }

Gereate all possible triplets, assign triplet IDs to the triplets and store them 
in a folder. 
Accessing these triplet files perform uniform random sampling to pick 
100 triplets and keep track of the triplet IDs picked for judgment in another folder. Note: The number of Triplets being sampled must be sampled as multiple 
of 4 due to the fact that a HIT contains four legal and one trap triplet.

\section{Generate HITs}
A HIT consists of five different triplets, of which one is a trap. There are two
different kinds of trap: identical and irrelevant trap. 
At this step every four sampled triplet is combined with a trap to form a HIT.
The HITs dataframe for each query is stored in the 'HIT' folder. 


\section{Submit HITs}

\emph{MTurkR} can be used to automatically submit jobs from R to Amazon Mechanical Turk. 




\end{document}